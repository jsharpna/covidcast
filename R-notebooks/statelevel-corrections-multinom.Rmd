---
title: "State deaths corrections with backfilling"
author: "Delphi Group"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    code_folding: hide
params:
  window_size: 14
  start_date: NULL
  sig_cut: 3
  size_cut: 20
  sig_consec: 2.25
  outlier_start_date: "2020-03-01"
  cache_data: FALSE
  backfill_lag: 14
  excess_cut: 0
  write_RDS: TRUE
---

```{r setup, warning=FALSE, message=FALSE}
library(covidcast)
library(dplyr)
library(tidyr)
library(forcats)
#library(tidyverse)
library(lubridate)
library(RcppRoll)
library(cowplot)
library(ggplot2)
library(DT)
knitr::opts_chunk$set(warning = FALSE, message=FALSE)
source("corrections-funs.R")
attach(params)
```


```{r grab-data, cache=params$cache_data}
states <-  suppressMessages(
  covidcast_signal(
  "jhu-csse","deaths_incidence_num", 
  geo_type = "state", 
  start_day = start_date)
)
```


```{r calculate-roll-stats}
states <- states %>% group_by(geo_value) %>% mutate(
  fmean = roll_meanr(value, window_size),
  smean = roll_mean(value, window_size, fill = NA),
  fmedian = roll_medianr(value, window_size),
  smedian = roll_median(value, window_size, fill = NA),
  fsd = roll_sdr(value, window_size),
  ssd = roll_sd(value, window_size,fill = NA),
  fmad = roll_medianr(abs(value-fmedian), window_size),
  smad = roll_median(abs(value-smedian), window_size, fill=NA),
  ftstat = abs(value-fmedian)/fsd, # mad in denominator is wrong scale, 
  ststat = abs(value-smedian)/ssd, # basically results in all the data flagged
  flag = 
    (abs(value) > size_cut & !is.na(ststat) & ststat > sig_cut) | # best case
    (is.na(ststat) & abs(value) > size_cut & !is.na(ftstat) & ftstat > sig_cut) | 
      # use filter if smoother is missing
    (value < -size_cut & !is.na(ststat) & !is.na(ftstat)), # big negative
    #(fmean > 10 & fmean< 20 & value > 2*sig_cut*fmean)
  flag = flag | # these allow smaller values to also be outliers if they are consecutive
    (dplyr::lead(flag) & !is.na(ststat) & ststat > sig_consec) | 
    (dplyr::lag(flag) & !is.na(ststat) & ststat > sig_consec) |
    (dplyr::lead(flag) & is.na(ststat) & ftstat > sig_consec) |
    (dplyr::lag(flag) & is.na(ststat) & ftstat > sig_consec),
  FIPS = as.numeric(STATE_TO_FIPS[toupper(geo_value)])
  )
```

## Outlier check

Just a visual to ensure that our flagged outliers catch anything that
Alden flagged when we did this manually. Also helps find coding errors in the
flagging procedure.


```{r fig.height = 30, fig.width = 10}
states_check = left_join(states, aldens_corrections) %>%
  mutate(geo_value = as.factor(geo_value))


states_check %>%
  dplyr::select(time_value, geo_value, value, fmedian, smedian) %>%
  pivot_longer(value:smedian) %>%
  mutate(name = fct_recode(
    name, observed="value", one_sided="fmedian", two_sided="smedian")) %>%
  ggplot(aes(time_value, value)) + geom_line(aes(color=name)) +
  geom_vline(data = filter(states_check,  varname), 
              aes(xintercept = time_value, color="alden")) +
  geom_point(data = filter(states_check, varname), 
             aes(y=imputed_val, color="alden")) +
  geom_point(data=filter(states_check, flag), aes(color="flagged")) +
  facet_wrap(.~geo_value,ncol=2,scales = 'free_y') + 
  theme_cowplot() + xlab("date") + 
  ylab(attributes(states)$metadata$signal) +
  scale_color_viridis_d()
```



## Numeric checks

Here we display the different flagged outliers as well as Alden's manual outliers.

```{r}
outliers <- outlier <- states_check %>% group_by(geo_value) %>% 
  filter(flag | varname) %>%
  select(geo_value, time_value, value, fmedian, smedian, 
         imputed_val, flag, ftstat, ststat)

datatable(
  outlier,
  options = list(scrollX = TRUE, scrollY = "300px",paging = FALSE),
  rownames = NULL) %>% 
  formatSignif(~fmedian+smedian+ftstat+ststat,3)
```


## Make corrections

Now we use the "multinomial" smoother to backfill the excess of any flagged outliers. Some notes:

* We use a new function `corrections_multinom_roll()` to do the backfill.
* It backfills randomly based on smoother as weights
* Optionally allows for filling non-uniformly.
* We treat the big New York outlier differently, it gets an infinite backfill.

```{r make-corrections}
corrected_states = states %>%
  mutate(
    # try using everything, not just the "excess"
    excess = value - na_replace(smedian, fmedian),
    excess = floor(excess - excess_cut*sign(excess)*na_replace(smad,fmad)),
    flag_big_ny = (geo_value == "ny" & time_value == ymd("2020-05-18")),
    corrected = corrections_multinom_roll(
      value, excess, flag_big_ny, time_value, FIPS, Inf, smedian),
    corrected = corrections_multinom_roll(
      corrected, excess, (flag & !flag_big_ny), 
      time_value, FIPS, backfill_lag),
    )
```

```{r show-corrections, fig.height = 30, fig.width = 10}
corrected_states %>%
  dplyr::select(geo_value, time_value, value, corrected, flag) %>%
  pivot_longer(value:corrected) %>%
  ggplot(aes(time_value)) + geom_line(aes(y=value,color=name)) +
  geom_point(data = filter(corrected_states, flag), aes(y=value), color="red") +
  facet_wrap(~geo_value, scales = "free_y", ncol = 2) +
  theme_cowplot() + xlab("date") + 
  ylab(attributes(states)$metadata$signal) +
  scale_color_viridis_d()
```

Because NY and OH each have oddities, so we check them specifically.

```{r corrected-ny-oh}
ny = corrected_states %>% filter(geo_value=="ny") %>% ungroup() 
ny_long = ny %>%
  dplyr::select(time_value, value, corrected, flag) %>%
  pivot_longer(value:corrected)
oh = corrected_states %>% filter(geo_value=="oh") %>% ungroup() 
oh_long = oh %>%
  dplyr::select(time_value, value, corrected, flag) %>%
  pivot_longer(value:corrected)

ggplot(ny_long, aes(time_value, value, color=name)) + geom_line() +
  geom_point(data = filter(ny, flag), aes(y=value), color="red") +
  theme_cowplot() + xlab("date") + 
  ylab(attributes(states)$metadata$signal) +
  scale_color_viridis_d()

ggplot(ny_long, aes(time_value, value, color=name)) + geom_line() +
  geom_point(data = filter(ny, flag), aes(y=value), color="red") +
  theme_cowplot() + xlab("date") + coord_cartesian(ylim=c(-50,1000))+
  ylab(attributes(states)$metadata$signal) +
  scale_color_viridis_d()

ggplot(oh_long, aes(time_value, value, color=name)) + geom_line() +
  geom_point(data = filter(oh, flag), aes(y=value), color="red") +
  theme_cowplot() + xlab("date") + 
  ylab(attributes(states)$metadata$signal) +
  scale_color_viridis_d()

  
```

## Show all corrected time points

```{r}
vectorized_ifelse <- function(test, yes, no){
  tmp = yes
  tmp[!test] = no[!test]
  tmp
}

sum_check = corrected_states %>%
  summarise(original = sum(value, na.rm=TRUE),
            corrected = sum(corrected, na.rm = TRUE)) %>% ungroup() %>%
  mutate(diffs = abs(original-corrected)) %>%
  summarise(trouble = any(diffs != 0L))

print(paste0("Any totals changed? ", sum_check))


tosave = corrected_states %>% 
  mutate(output = abs(corrected - value) > 0) %>%
  filter(output) %>% ungroup() %>%
  dplyr::select(geo_value, time_value, value, corrected) %>%
  transmute(
    location_name = toupper(geo_value), 
    value = corrected,
    issue_date = as.Date(NA),
    variable_name = "jhu-csse_deaths_incidence_num",
    location = STATE_TO_FIPS[location_name],
    reference_date = time_value) %>%
  filter(reference_date >= params$outlier_start_date) %>%
  dplyr::select(location, location_name, reference_date, issue_date,
                variable_name, value)

corrected_states %>% 
  mutate(output = abs(corrected - value) > 0) %>%
  filter(output) %>%
  dplyr::select(geo_value, time_value, value, corrected) %>%
  transmute(time_value=time_value, 
            geo_value=geo_value,
            orig_value = value,
            replacement = corrected
            ) %>%
  datatable(
    options = list(scrollX = TRUE, scrollY = "300px",paging = FALSE),
    rownames = NULL) 
```

```{r eval=params$write_RDS}
saveRDS(tosave, file="state_corrections_djm.RDS")
```







